{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59a9e24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3eecc0",
   "metadata": {},
   "source": [
    "## 1. Basic Data Engineering for Each Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b534e9bf",
   "metadata": {},
   "source": [
    "## 1.1 Property Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010ef642",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb8cad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_df = pd.read_csv(\"../data/landing/properties.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1c69df",
   "metadata": {},
   "source": [
    "### Basic Information Of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18816971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NA in property_type: 1\n",
      "Number of NA in geo: 4970\n",
      "Number of NA in age_distribution: 0\n",
      "Number of NA in nearby_schools: 0\n",
      "Number of NA in parking: 1\n",
      "Number of NA in agency: 0\n",
      "Number of NA in nbn_type: 1966\n",
      "Number of NA in price: 1411\n",
      "Number of NA in bedrooms: 1\n",
      "Number of NA in location: 1\n",
      "Number of NA in area: 0\n",
      "Number of NA in bathrooms: 1\n"
     ]
    }
   ],
   "source": [
    "for a_feature in list(property_df.columns):\n",
    "    na_count = property_df[a_feature].isna().sum()\n",
    "    print(f\"Number of NA in {a_feature}: {na_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd84baa",
   "metadata": {},
   "source": [
    "### Required Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "14c87daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_price(price):\n",
    "    if pd.isna(price) or price == '':\n",
    "        return None\n",
    "    \n",
    "    # 使用改进的正则表达式\n",
    "    match = re.search(r'(\\d+(?:,\\d+)*(?:\\.\\d+)?)\\s*(pw|pcm|per week|per month)?', str(price), re.IGNORECASE)\n",
    "    \n",
    "    if match:\n",
    "        # 移除非数字字符并转换为浮点数\n",
    "        clean_price_str = re.sub(r'[^\\d.]', '', match.group(1))\n",
    "        \n",
    "        try:\n",
    "            price_value = float(clean_price_str)\n",
    "        except ValueError:\n",
    "            return None\n",
    "\n",
    "        # 如果是每月价格，转换为每周价格\n",
    "        if match.group(2) and ('m' in match.group(2).lower() or 'month' in match.group(2).lower()):\n",
    "            price_value /= 4.3  # 假设一个月平均4.3周\n",
    "\n",
    "        return round(price_value, 2)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def parse_location(location_str):\n",
    "    if pd.isna(location_str):\n",
    "        return pd.Series({'streetAddress': None, 'addressLocality': None, 'addressRegion': None, 'postalCode': None})\n",
    "    location_dict = ast.literal_eval(location_str)\n",
    "    return pd.Series(location_dict)\n",
    "\n",
    "def parse_age_dist(age_dist_str):\n",
    "    if pd.isna(age_dist_str):\n",
    "        return None\n",
    "    age_dist_dict = ast.literal_eval(age_dist_str)\n",
    "    for key, value in age_dist_dict.items():\n",
    "        value = value.strip().rstrip('%')\n",
    "        value = float(value)\n",
    "        if value >= 50:\n",
    "            return key\n",
    "    \n",
    "    return 'balanced age' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fb206d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_properties(property_df):\n",
    "    property_df[['bedrooms', 'bathrooms', 'parking']] = property_df[['bedrooms', 'bathrooms', 'parking']].fillna(0)\n",
    "    \n",
    "    # price\n",
    "    property_df['price'] = property_df['price'].apply(clean_price)\n",
    "\n",
    "    # location\n",
    "    location_df = property_df['location'].apply(parse_location)\n",
    "    property_df = pd.concat([property_df.drop('location', axis=1), location_df], axis=1)\n",
    "    \n",
    "    # age distribution\n",
    "    property_df['age_distribution'] = property_df['age_distribution'].apply(parse_age_dist)\n",
    "    \n",
    "    property_df = property_df.dropna(subset=['price', 'streetAddress', 'addressLocality', 'postalCode'])\n",
    "    \n",
    "    property_df = property_df[[\n",
    "    'streetAddress', 'price', 'bedrooms', 'bathrooms', 'parking',\n",
    "    'addressLocality', 'addressRegion', 'postalCode', 'property_type', \n",
    "    'nearby_schools', 'nbn_type', 'age_distribution', 'geo'\n",
    "    ]]\n",
    "    \n",
    "    return property_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1f567b",
   "metadata": {},
   "source": [
    "### Apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d65eb264",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_df = clean_properties(property_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08613e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#property_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2d67d1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../data/raw/cleaned_properties.csv\"\n",
    "property_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072f64bc",
   "metadata": {},
   "source": [
    "## 1.2 Other Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01748a6",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "20bfbeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_df = pd.read_csv(\"../data/landing/hospital_health_services_addresses.csv\")\n",
    "park_df = pd.read_csv(\"../data/landing/park.csv\")\n",
    "station_df = pd.read_csv(\"../data/landing/stations_and_suburbs.csv\")\n",
    "shopping_cen_df = pd.read_csv(\"../data/landing/victoria_shopping_centres.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b442a9f",
   "metadata": {},
   "source": [
    "### Required Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb78de9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_postcode(address):\n",
    "    match = re.search(r'\\b(\\d{4})\\b$', address)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4bd0eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indicate_melbourne_suburbs(suburb):\n",
    "    melbourne_suburbs = ['flagstaff', 'parliament', 'melbourne central', 'flinders street', 'southern cross']\n",
    "    \n",
    "    if pd.isna(suburb):\n",
    "        return suburb\n",
    "    \n",
    "    suburb_lower = suburb.lower().strip()\n",
    "    \n",
    "    if suburb_lower in melbourne_suburbs:\n",
    "        return 'Melbourne'\n",
    "    else:\n",
    "        return suburb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f965bac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_suburb(region, address):\n",
    "    indy_suburbs = ['southbank', 'docklands']\n",
    "    \n",
    "    if region == 'Melbourne CBD':\n",
    "        suburb = address.split(',')[-1].strip()\n",
    "        suburb_lower = suburb.lower().strip()\n",
    "        if suburb_lower in indy_suburbs:\n",
    "            return suburb\n",
    "        else:\n",
    "            return 'Melbourne'\n",
    "    \n",
    "    elif region == 'Geelong':\n",
    "        if ',' in address:\n",
    "            suburb = address.split(',')[-1].strip()\n",
    "            return suburb\n",
    "        else:\n",
    "            return 'Geelong'\n",
    "    \n",
    "    else:\n",
    "        suburb = address.split(',')[-1].strip()\n",
    "        if '(' in suburb:\n",
    "            return suburb.split('(')[0].strip()\n",
    "        return suburb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4914b163",
   "metadata": {},
   "source": [
    "### Apply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7bf42f",
   "metadata": {},
   "source": [
    "Hospital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3621768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_df['postalCode'] = hospital_df['Address'].apply(get_postcode)\n",
    "hospital_df = hospital_df.rename(columns={'Address': 'hospital_address'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f980655c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../data/raw/cleaned_hospital_health_services_addresses.csv\"\n",
    "hospital_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edaa941",
   "metadata": {},
   "source": [
    "Park"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "355eabb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['ID'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m park_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpostalCode\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m park_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAddress\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(get_postcode)\n\u001b[1;32m      2\u001b[0m park_df \u001b[38;5;241m=\u001b[39m park_df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAddress\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpark_address\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m----> 3\u001b[0m park_df \u001b[38;5;241m=\u001b[39m park_df\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:5344\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5197\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5198\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5205\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5206\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5208\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5209\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5342\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5343\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[1;32m   5345\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m   5346\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   5347\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[1;32m   5348\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m   5349\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[1;32m   5350\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[1;32m   5351\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m   5352\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:4711\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4709\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4711\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4714\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:4753\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4751\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4753\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4754\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4756\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4757\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:7000\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6998\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 7000\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7001\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   7002\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['ID'] not found in axis\""
     ]
    }
   ],
   "source": [
    "park_df['postalCode'] = park_df['Address'].apply(get_postcode)\n",
    "park_df = park_df.rename(columns={'Address': 'park_address'})\n",
    "park_df = park_df.drop('ID', a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b2858e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../data/raw/cleaned_park.csv\"\n",
    "park_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d99059",
   "metadata": {},
   "source": [
    "Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f02fb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df['addressLocality'] = station_df['Station'].apply(indicate_melbourne_suburbs)\n",
    "station_df = station_df.drop('Station', axis = 1)\n",
    "station_df = station_df.rename(columns={'Suburb': 'Station'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d775f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../data/raw/cleaned_stations_and_suburbs.csv\"\n",
    "station_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a8a60b",
   "metadata": {},
   "source": [
    "Shopping Center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b84f32d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "shopping_cen_df['addressLocality'] = shopping_cen_df.apply(lambda row: get_suburb(row['Region'], \n",
    "                                                                                 row['Shopping Centre']), axis=1)\n",
    "shopping_cen_df = shopping_cen_df.drop('Region', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72280e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../data/raw/cleaned_victoria_shopping_centres.csv\"\n",
    "shopping_cen_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be6394a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
