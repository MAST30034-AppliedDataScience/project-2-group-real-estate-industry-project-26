{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59a9e24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3eecc0",
   "metadata": {},
   "source": [
    "## 1. Basic Data Engineering for Each Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a52ec9b",
   "metadata": {},
   "source": [
    "## 1.1 Property Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010ef642",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb8cad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_df = pd.read_csv(\"../data/landing/properties.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1c69df",
   "metadata": {},
   "source": [
    "### Basic Information Of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18816971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NA in property_type: 1\n",
      "Number of NA in nearby_schools: 0\n",
      "Number of NA in bedrooms: 1\n",
      "Number of NA in age_distribution: 0\n",
      "Number of NA in agency: 0\n",
      "Number of NA in parking: 1\n",
      "Number of NA in area: 0\n",
      "Number of NA in geo: 1\n",
      "Number of NA in bathrooms: 1\n",
      "Number of NA in price: 1\n",
      "Number of NA in location: 1\n",
      "Number of NA in nbn_type: 1949\n"
     ]
    }
   ],
   "source": [
    "for a_feature in list(property_df.columns):\n",
    "    na_count = property_df[a_feature].isna().sum()\n",
    "    print(f\"Number of NA in {a_feature}: {na_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd84baa",
   "metadata": {},
   "source": [
    "### Required Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14c87daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_price(price):\n",
    "    if pd.isna(price) or price == '':\n",
    "        return None\n",
    "    \n",
    "    # 使用改进的正则表达式\n",
    "    match = re.search(r'(\\d+(?:,\\d+)*(?:\\.\\d+)?)\\s*(pw|pcm|per week|per month)?', str(price), re.IGNORECASE)\n",
    "    \n",
    "    if match:\n",
    "        # 移除非数字字符并转换为浮点数\n",
    "        clean_price_str = re.sub(r'[^\\d.]', '', match.group(1))\n",
    "        \n",
    "        try:\n",
    "            price_value = float(clean_price_str)\n",
    "        except ValueError:\n",
    "            return None\n",
    "\n",
    "        # 如果是每月价格，转换为每周价格\n",
    "        if match.group(2) and ('m' in match.group(2).lower() or 'month' in match.group(2).lower()):\n",
    "            price_value /= 4.3  # 假设一个月平均4.3周\n",
    "\n",
    "        return round(price_value, 2)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def parse_location(location_str):\n",
    "    if pd.isna(location_str):\n",
    "        return pd.Series({'streetAddress': None, 'addressLocality': None, 'addressRegion': None, 'postalCode': None})\n",
    "    location_dict = ast.literal_eval(location_str)\n",
    "    return pd.Series(location_dict)\n",
    "\n",
    "def parse_age_dist(age_dist_str):\n",
    "    if pd.isna(age_dist_str):\n",
    "        return None\n",
    "    age_dist_dict = ast.literal_eval(age_dist_str)\n",
    "    for key, value in age_dist_dict.items():\n",
    "        value = value.strip().rstrip('%')\n",
    "        value = float(value)\n",
    "        if value >= 50:\n",
    "            return key\n",
    "    \n",
    "    return 'balanced age' \n",
    "\n",
    "def count_schools(school_list):\n",
    "    try:\n",
    "        schools = ast.literal_eval(school_list)\n",
    "        return len(schools)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb206d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_properties(property_df):\n",
    "    property_df[['bedrooms', 'bathrooms', 'parking']] = property_df[['bedrooms', 'bathrooms', 'parking']].fillna(0)\n",
    "    \n",
    "    # price\n",
    "    property_df['price'] = property_df['price'].apply(clean_price)\n",
    "\n",
    "    # location\n",
    "    location_df = property_df['location'].apply(parse_location)\n",
    "    property_df = pd.concat([property_df.drop('location', axis=1), location_df], axis=1)\n",
    "    \n",
    "    # age distribution\n",
    "    property_df['age_distribution'] = property_df['age_distribution'].apply(parse_age_dist)\n",
    "    \n",
    "    # school count\n",
    "    property_df['school_count'] = property_df['nearby_schools'].apply(count_schools)\n",
    "    \n",
    "    property_df = property_df.dropna(subset=['price', 'streetAddress', 'addressLocality', 'postalCode', \n",
    "                                             'geo', 'property_type'])\n",
    "    \n",
    "    property_df = property_df[[\n",
    "    'streetAddress', 'price', 'bedrooms', 'bathrooms', 'parking',\n",
    "    'addressLocality', 'addressRegion', 'postalCode', 'property_type', \n",
    "    'school_count', 'nbn_type', 'age_distribution', 'nearby_schools', 'geo'\n",
    "    ]]\n",
    "    \n",
    "    return property_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ddf05b",
   "metadata": {},
   "source": [
    "### Apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d65eb264",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_df = clean_properties(property_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d67d1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../data/raw/cleaned_properties.csv\"\n",
    "property_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb56730",
   "metadata": {},
   "source": [
    "## 1.2 Other Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadfb255",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5ffb677",
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_df = pd.read_csv(\"../data/landing/hospital_health_services_addresses.csv\")\n",
    "park_df = pd.read_csv(\"../data/landing/park.csv\")\n",
    "station_df = pd.read_csv(\"../data/landing/stations_and_suburbs.csv\")\n",
    "shopping_cen_df = pd.read_csv(\"../data/landing/victoria_shopping_centres.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334dc1cf",
   "metadata": {},
   "source": [
    "### Required Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9cb2d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_postcode(address):\n",
    "    match = re.search(r'\\b(\\d{4})\\b$', address)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5281fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indicate_melbourne_suburbs(suburb):\n",
    "    melbourne_suburbs = ['flagstaff', 'parliament', 'melbourne central', 'flinders street', 'southern cross']\n",
    "    \n",
    "    if pd.isna(suburb):\n",
    "        return suburb\n",
    "    \n",
    "    suburb_lower = suburb.lower().strip()\n",
    "    \n",
    "    if suburb_lower in melbourne_suburbs:\n",
    "        return 'Melbourne'\n",
    "    else:\n",
    "        return suburb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6af24afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_suburb(region, address):\n",
    "    indy_suburbs = ['southbank', 'docklands']\n",
    "    \n",
    "    if region == 'Melbourne CBD':\n",
    "        suburb = address.split(',')[-1].strip()\n",
    "        suburb_lower = suburb.lower().strip()\n",
    "        if suburb_lower in indy_suburbs:\n",
    "            return suburb\n",
    "        else:\n",
    "            return 'Melbourne'\n",
    "    \n",
    "    elif region == 'Geelong':\n",
    "        if ',' in address:\n",
    "            suburb = address.split(',')[-1].strip()\n",
    "            return suburb\n",
    "        else:\n",
    "            return 'Geelong'\n",
    "    \n",
    "    else:\n",
    "        suburb = address.split(',')[-1].strip()\n",
    "        if '(' in suburb:\n",
    "            return suburb.split('(')[0].strip()\n",
    "        return suburb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e711d7",
   "metadata": {},
   "source": [
    "### Apply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fe3171",
   "metadata": {},
   "source": [
    "Hospital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7e7bd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_df['postalCode'] = hospital_df['Address'].apply(get_postcode)\n",
    "hospital_df = hospital_df.rename(columns={'Address': 'hospital_address'})\n",
    "\n",
    "hosipital_counts = hospital_df.groupby('postalCode').size().reset_index(name='hosipital_count')\n",
    "hospital_df = hospital_df.merge(hosipital_counts, on='postalCode', how='left')\n",
    "\n",
    "hospital_df = hospital_df.drop('hospital_address', axis=1)\n",
    "hospital_df = hospital_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "827a235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../data/raw/cleaned_hospital_health_services_addresses.csv\"\n",
    "hospital_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76126dd6",
   "metadata": {},
   "source": [
    "Park"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5322d2c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "park_df['postalCode'] = park_df['Address'].apply(get_postcode)\n",
    "park_df = park_df.rename(columns={'Address': 'park_address'})\n",
    "\n",
    "park_counts = park_df.groupby('postalCode').size().reset_index(name='park_count')\n",
    "park_df = park_df.merge(park_counts, on='postalCode', how='left')\n",
    "\n",
    "park_df = park_df.drop(['park_address', 'ID'], axis=1)\n",
    "park_df = park_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "584083c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../data/raw/cleaned_park.csv\"\n",
    "park_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7101fa",
   "metadata": {},
   "source": [
    "Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b2185d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df['addressLocality'] = station_df['Station'].apply(indicate_melbourne_suburbs)\n",
    "station_df = station_df.drop('Station', axis = 1)\n",
    "station_df = station_df.rename(columns={'Suburb': 'Station'})\n",
    "\n",
    "station_counts = station_df.groupby('addressLocality').size().reset_index(name='station_count')\n",
    "station_df = station_df.merge(station_counts, on='addressLocality', how='left')\n",
    "\n",
    "station_df = station_df.drop(['Station'], axis=1)\n",
    "station_df = station_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "711d90ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../data/raw/cleaned_stations_and_suburbs.csv\"\n",
    "station_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6062930",
   "metadata": {},
   "source": [
    "Shopping Center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f31c0bad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "shopping_cen_df['addressLocality'] = shopping_cen_df.apply(lambda row: get_suburb(row['Region'], \n",
    "                                                                                 row['Shopping Centre']), axis=1)\n",
    "\n",
    "shopping_cen_counts = shopping_cen_df.groupby('addressLocality').size().reset_index(name='shopping_cen_count')\n",
    "shopping_cen_df = shopping_cen_df.merge(shopping_cen_counts, on='addressLocality', how='left')\n",
    "\n",
    "shopping_cen_df = shopping_cen_df.drop(['Region', 'Shopping Centre'], axis=1)\n",
    "shopping_cen_df = shopping_cen_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "045105e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../data/raw/cleaned_victoria_shopping_centres.csv\"\n",
    "shopping_cen_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587d44c2",
   "metadata": {},
   "source": [
    "## 2. Data Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d8079fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.merge(property_df, hospital_df, on='postalCode', how='left')\n",
    "final_df = pd.merge(final_df, park_df, on='postalCode', how='left')\n",
    "final_df = pd.merge(final_df, station_df, on='addressLocality', how='left')\n",
    "final_df = pd.merge(final_df, shopping_cen_df, on='addressLocality', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5dbeb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_l = ['hosipital_count', 'park_count', 'station_count', 'shopping_cen_count']\n",
    "final_df[feature_l] = final_df[feature_l].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34d2f848",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../data/curated/combined_data.csv\"\n",
    "final_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5005fa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
